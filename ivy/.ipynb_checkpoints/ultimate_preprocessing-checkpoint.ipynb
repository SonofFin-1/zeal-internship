{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbc5fd4e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdfminer in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (20191125)\n",
      "Requirement already satisfied: pycryptodome in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer) (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdfminer.six in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (20231228)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer.six) (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: docx2txt in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-pptx in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.6.23)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from python-pptx) (5.2.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /opt/homebrew/lib/python3.12/site-packages (from python-pptx) (10.3.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from python-pptx) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pinecone in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from pinecone) (2024.6.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pinecone-client in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (4.1.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from pinecone-client) (2024.6.2)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "env: OPENAI_API_KEY=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\n",
      "env: PINECONE_API_KEY=96912940-e64b-4d5f-8bef-759f23f269f0\n",
      "env: environment=ENV\n",
      "Here is your OpenAI API Key: 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\n",
      "Here is your Pinecone API Key: 96912940-e64b-4d5f-8bef-759f23f269f0\n",
      "SHELL=/opt/homebrew/bin/bash\n",
      "WINDOWID=73031\n",
      "PYENV_HOOK_PATH=/Users/jojo/.pyenv/pyenv.d:/opt/homebrew/Cellar/pyenv/2.4.2/pyenv.d:/opt/homebrew/etc/pyenv.d:/etc/pyenv.d:/usr/lib/pyenv/hooks\n",
      "NVM_RC_VERSION=\n",
      "COLORTERM=truecolor\n",
      "PYENV_SHELL=bash\n",
      "XPC_FLAGS=0x0\n",
      "__CFBundleIdentifier=net.kovidgoyal.kitty\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.gAF0o6Oc35/Listeners\n",
      "OPENAI_API_KEY=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\n",
      "PYENV_VIRTUALENV_DISABLE_PROMPT=1\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "KITTY_PID=1065\n",
      "EDITOR=vi\n",
      "PYENV_VERSION=3.12.2\n",
      "PWD=/Users/jojo/dev/zeal/ivy\n",
      "PYENV_VIRTUALENV_INIT=1\n",
      "LOGNAME=jojo\n",
      "JPY_SESSION_NAME=/Users/jojo/dev/zeal/ivy/ultimate_preprocessing.ipynb\n",
      "MANPATH=/opt/homebrew/share/man:/usr/share/man:/usr/local/share/man:/Applications/kitty.app/Contents/Resources/man::\n",
      "KITTY_PUBLIC_KEY=1:uZ*0B{<2oEP5mHXzzxLPB4ZH(6YJ-wSRBrExY9sP\n",
      "COMMAND_MODE=unix2003\n",
      "LDFLAGS=-L/opt/homebrew/opt/llvm/lib/c++ -Wl,-rpath,/opt/homebrew/opt/llvm/lib/c++\n",
      "HOME=/Users/jojo\n",
      "LANG=en_US.UTF-8\n",
      "KITTY_WINDOW_ID=32\n",
      "FORCE_COLOR=1\n",
      "TMPDIR=/var/folders/bb/rwf_bc6n7hjbvrbbxm8rwkd00000gn/T/\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CPPFLAGS=-I/opt/homebrew/opt/llvm/include\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "BASH_SILENCE_DEPRECATION_WARNING=1\n",
      "PYENV_DIR=/Users/jojo/dev/zeal/ivy\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "NVM_DIR=/Users/jojo/.nvm\n",
      "JPY_PARENT_PID=93045\n",
      "TERM=xterm-color\n",
      "TERMINFO=/Applications/kitty.app/Contents/Resources/kitty/terminfo\n",
      "environment=ENV\n",
      "USER=jojo\n",
      "GIT_PAGER=cat\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "SHLVL=1\n",
      "NVM_CD_FLAGS=\n",
      "PAGER=cat\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "XPC_SERVICE_NAME=0\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "PYENV_ROOT=/Users/jojo/.pyenv\n",
      "PATH=/opt/homebrew/Cellar/pyenv/2.4.2/libexec:/opt/homebrew/Cellar/pyenv/2.4.2/plugins/python-build/bin:/Users/jojo/bin:/opt/homebrew/share/google-cloud-sdk/bin:/opt/homebrew/opt/llvm/bin:/opt/homebrew/Cellar/pyenv-virtualenv/1.2.3/shims:/Users/jojo/.pyenv/shims:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Apple/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Applications/kitty.app/Contents/MacOS:/Users/jojo/.pyenv/:/opt/homebrew/opt/fzf/bin:/Users/jojo/.spicetify/\n",
      "PINECONE_API_KEY=96912940-e64b-4d5f-8bef-759f23f269f0\n",
      "KITTY_INSTALLATION_DIR=/Applications/kitty.app/Contents/Resources/kitty\n",
      "OLDPWD=/Users/jojo/dev/zeal\n",
      "__CF_USER_TEXT_ENCODING=0x1F5:0x0:0x0\n",
      "_=/usr/bin/printenv\n"
     ]
    }
   ],
   "source": [
    "# pip install packages\n",
    "%pip install openai==0.28\n",
    "%pip install tiktoken\n",
    "%pip install pdfminer\n",
    "%pip install pdfminer.six\n",
    "%pip install docx2txt\n",
    "%pip install python-pptx\n",
    "# %pip install pinecone-client==2.2.4\n",
    "%pip install pinecone\n",
    "%pip install pinecone-client --upgrade\n",
    "\n",
    "\n",
    "\n",
    "# imports\n",
    "import openai\n",
    "import os\n",
    "import tiktoken\n",
    "from tqdm.auto import tqdm     # this is our progress bar\n",
    "import pinecone\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text, extract_pages\n",
    "import docx2txt\n",
    "from pptx import Presentation\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "# constants\n",
    "GPT_MODEL = 'gpt-4o'\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "\n",
    "# this is for the input data\n",
    "PATH = 'data\\\\temp-financial'\n",
    "\n",
    "# these are Pinecone vars\n",
    "INDEX = 'idx'\n",
    "ENV = 'us-east-1-aws'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "# pinecone = Pinecone(api_key=\"4f53edcf-73a4-4fc6-9d04-117538bf0850\")\n",
    "\n",
    "# env vars\n",
    "%env OPENAI_API_KEY=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\n",
    "%env PINECONE_API_KEY=96912940-e64b-4d5f-8bef-759f23f269f0\n",
    "%env environment=ENV\n",
    "\n",
    "\n",
    "# store keys for OpenAI and Pinecone\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "print(f\"Here is your OpenAI API Key: {openai.api_key}\")\n",
    "print(f\"Here is your Pinecone API Key: {os.environ['PINECONE_API_KEY']}\")\n",
    "\n",
    "\n",
    "# check your system environment variables\n",
    "!printenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d17aa4-f9f9-4f08-99a5-b7adda0310ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c224b50-8793-4c1d-b258-182d75a59402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4b007-de7a-4193-b9d7-b93888e9921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f9c9b-1683-4bdd-bf77-36fffdbcf227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b269c26-9ad3-4541-8dba-dbc983ea0a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00b1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = 'gpt-4') -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adb25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af786385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    return extract_text(path).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823e649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(path):\n",
    "    # extract text\n",
    "    \n",
    "    return docx2txt.process(path).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf5bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pptx(path):\n",
    "    split = []\n",
    "    prs = Presentation(path)\n",
    "    print(\"----------------------\")\n",
    "    temp = ''\n",
    "    enterCount = 0\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, 'text'):\n",
    "#                 if len(shape.text) > 0:\n",
    "#                     temp += shape.text\n",
    "#                 elif enterCount > 1:\n",
    "#                     split.append(temp)\n",
    "#                     temp = ''\n",
    "#                     enterCount = 0\n",
    "#                 elif len(shape.text) == 0:\n",
    "#                     enterCount += 1\n",
    "                split.append(shape.text)\n",
    "    \n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04189e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xlsx(path):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(PATH)\n",
    "    \n",
    "    xml_file = os.path.join(PATH, 'xl/sharedStrings.xml')\n",
    "    \n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for elem in root.iter():\n",
    "        if elem.text:\n",
    "            result.append(elem.text.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82080044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "        openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "        print(openai.api_key)\n",
    "\n",
    "        #client = OpenAI(\n",
    "            # This is the default and can be omitted\n",
    "         #   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        #)\n",
    "        \n",
    "        messages = [\n",
    "            { 'role': 'system', 'content': 'system message here' },\n",
    "            { 'role': 'user', 'content': [\n",
    "                {'type': 'text', 'text': f'Convert the following image into a text table.'},\n",
    "                {'type': 'image_url', 'image_url': { 'url': f'data:image/png;base64,{image}'} }\n",
    "            ]}\n",
    "        ]\n",
    "        \n",
    "        functions = [\n",
    "            {\n",
    "                'name': 'write_queries',\n",
    "                'description': 'Get information from the database',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'details': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The information needed from the database',\n",
    "                        },\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        \n",
    "        result = ''\n",
    "        \n",
    "        for chunk in openai.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=messages,\n",
    "            functions=functions,\n",
    "            temperature=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            function_call=None,\n",
    "            stream=True\n",
    "        ):\n",
    "            if len(chunk.choices) > 0:\n",
    "                response = chunk.choices[0]\n",
    "                finish_reason = response.finish_reason\n",
    "                content = response.delta.content\n",
    "                function = response.delta.function_call\n",
    "\n",
    "                if content is not None:\n",
    "                    print(content, end='')\n",
    "                    result += content\n",
    "        \n",
    "        return result.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f888cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_files(root_path):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88364573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(s, delimiter = '.'):\n",
    "    parts = s.split(delimiter)\n",
    "    return delimiter.join(parts[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7859f9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "files = collect_all_files(PATH)\n",
    "\n",
    "lines = []\n",
    "for file in files:\n",
    "    lines = []\n",
    "    print(file)\n",
    "    suffix = get_range(file)\n",
    "    if suffix == 'txt':\n",
    "        lines = read_txt(file)\n",
    "    elif suffix == 'pdf':\n",
    "        lines = read_pdf(file)\n",
    "    elif suffix == 'docx':\n",
    "        lines = read_docx(file)\n",
    "    elif suffix == 'pptx':\n",
    "        lines = read_pptx(file)\n",
    "    elif suffix == 'xlsx':\n",
    "        lines = read_xlsx(file)\n",
    "    elif suffix == 'png':\n",
    "        lines = read_png(file)\n",
    "\n",
    "    temp_string = []\n",
    "    print(lines)\n",
    "    for line in lines:\n",
    "        if num_tokens('\\n'.join(temp_string)) > 256:\n",
    "            print('\\n'.join(temp_string))\n",
    "            messages.append('\\n'.join(temp_string))\n",
    "            temp_string = []\n",
    "        else:\n",
    "            temp_string.append(line)\n",
    "    if num_tokens('\\n'.join(temp_string)) < 256:\n",
    "        print('\\n'.join(temp_string))\n",
    "        messages.append('\\n'.join(temp_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470b5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [message for message in messages if len(message) > 0]\n",
    "\n",
    "if not messages: \n",
    "    messages = [\"this is message 1\", \"this is message 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5fd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is message 1', 'this is message 2']\n"
     ]
    }
   ],
   "source": [
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab3f544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 127\n"
     ]
    }
   ],
   "source": [
    "# calculate embeddings\n",
    "BATCH_SIZE = 128  # you can submit up to 2048 embedding inputs per request\n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(messages), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = messages[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response['data']):\n",
    "        assert i == be['index']  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e['embedding'] for e in response['data']]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({'text': messages, 'embedding': embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcaf89d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "#pinecone.init(\n",
    "#    api_key=os.environ['PINECONE_API_KEY'],\n",
    "#    environment=ENV  # find next to API key in console\n",
    "#)\n",
    "\n",
    "# print(embeddings)\n",
    "\n",
    "#index_name = \"idx\"\n",
    "# index_name = \"zeal/idx\"\n",
    "# index_name = \"quickstart\"\n",
    "\n",
    "\n",
    "# connect to your Pinecone index\n",
    "# index = pinecone.Index(index_name)\n",
    "\n",
    "\n",
    "# check if INDEX index already exists (only create index if not)\n",
    "#if index_name not in pinecone.list_indexes():\n",
    "#    pinecone.create_index(index_name, dimension=len(df['embedding'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a373b8-fc6f-4fd6-9669-257551b68064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc54c25-8dd1-467d-ad02-2b9b7c741d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "INDEX = 'idx'\n",
    "os.environ['PINECONE_API_KEY'] = '96912940-e64b-4d5f-8bef-759f23f269f0'\n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "# pc = Pinecone(api_key=\"96912940-e64b-4d5f-8bef-759f23f269f0\")\n",
    "\n",
    "if INDEX not in pc.list_indexes().names():\n",
    "    pc.create_index(INDEX, dimension=1536, metric='cosine', spec=PodSpec(environment=ENV))\n",
    "# connect to index\n",
    "index = pc.Index(INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f7bae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(df['text']), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(df['text']))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = df['text'][i:i+batch_size]\n",
    "    embeds = df['embedding'][i:i+batch_size]\n",
    "    ids_batch = ['training:' + str(n) for n in range(i, i_end)]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20428ad6-e9eb-4780-b125-a815a247b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_embeddings(query: str = '', embeddings: dict = {}, max_tokens: int = 1024) -> str:\n",
    "    '''Return the max_tokens amount of related contexts based on the query string.\n",
    "\n",
    "    Keyword arguments:\n",
    "    query -- The query needing context\n",
    "    embeddings -- The list of embeddings and text\n",
    "    max_tokens -- The number of tokens to pull (Default 1024)\n",
    "\n",
    "    Returns:\n",
    "    The context of the query\n",
    "    '''\n",
    "    embedding = openai.Embedding.create(model=EMBEDDING_MODEL, input=query)['data'][0]['embedding']\n",
    "    context = [message for _, message in sorted(zip(cosine_similarity(embeddings['embedding'], [embedding]), embeddings['text']), reverse=True)]\n",
    "\n",
    "    max_tokens = int(max_tokens)\n",
    "\n",
    "    text = ''\n",
    "    total_tokens = 0\n",
    "    max_tokens = min(num_tokens('\\n'.join(context)) + total_tokens + 1, max_tokens + 1)\n",
    "    i = 0\n",
    "\n",
    "    for item in context:\n",
    "        nxt = f'\\n{item}\\n'\n",
    "        total_tokens += num_tokens(nxt)\n",
    "        if total_tokens > max_tokens:\n",
    "            break\n",
    "        text += nxt\n",
    "        i += 1\n",
    "\n",
    "    return f'{text}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
