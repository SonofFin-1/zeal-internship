{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc5fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 0.28.0\n",
      "Uninstalling openai-0.28.0:\n",
      "  Successfully uninstalled openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdfminer in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (20191125)\n",
      "Requirement already satisfied: pycryptodome in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer) (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdfminer.six in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (20231228)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pdfminer.six) (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: docx2txt in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-pptx in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (0.6.23)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from python-pptx) (5.2.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /opt/homebrew/lib/python3.12/site-packages (from python-pptx) (10.3.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from python-pptx) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pinecone in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from pinecone) (2024.6.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pinecone-client in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (4.1.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from pinecone-client) (2024.6.2)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (from pinecone-client) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "env: environment=ENV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pip install packages\n",
    "%pip uninstall openai --yes\n",
    "%pip install openai==0.28\n",
    "%pip install tiktoken\n",
    "%pip install pdfminer\n",
    "%pip install pdfminer.six\n",
    "%pip install docx2txt\n",
    "%pip install python-pptx\n",
    "# %pip install pinecone-client==2.2.4\n",
    "%pip install pinecone\n",
    "%pip install pinecone-client --upgrade\n",
    "\n",
    "\n",
    "\n",
    "# imports\n",
    "import openai\n",
    "#from openai import OpenAI\n",
    "import os\n",
    "import tiktoken\n",
    "from tqdm.auto import tqdm     # this is our progress bar\n",
    "import pinecone\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text, extract_pages\n",
    "import docx2txt\n",
    "from pptx import Presentation\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "# constants\n",
    "GPT_MODEL = 'gpt-4o'\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "\n",
    "# this is for the input data\n",
    "PATH = 'data\\\\temp-financial'\n",
    "\n",
    "# these are Pinecone vars\n",
    "INDEX = 'idx'\n",
    "\n",
    "ENV = os.getenv(\"ENV\")\n",
    "\n",
    "\n",
    "\n",
    "# env vars\n",
    "%env environment=ENV\n",
    "\n",
    "\n",
    "# store keys for OpenAI and Pinecone\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "#print(f\"Here is your OpenAI API Key: {openai.api_key}\")\n",
    "# print(f\"Here is your Pinecone API Key: {os.environ['PINECONE_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff33871a-c7d5-4ddf-886b-ff3cc119cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "env: PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#%env OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
    "%env PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00b1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = 'gpt-4') -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adb25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af786385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    return extract_text(path).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823e649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(path):\n",
    "    # extract text\n",
    "    return docx2txt.process(path).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf5bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pptx(path):\n",
    "    split = []\n",
    "    prs = Presentation(path)\n",
    "    print(\"----------------------\")\n",
    "    temp = ''\n",
    "    enterCount = 0\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, 'text'):\n",
    "#                 if len(shape.text) > 0:\n",
    "#                     temp += shape.text\n",
    "#                 elif enterCount > 1:\n",
    "#                     split.append(temp)\n",
    "#                     temp = ''\n",
    "#                     enterCount = 0\n",
    "#                 elif len(shape.text) == 0:\n",
    "#                     enterCount += 1\n",
    "                split.append(shape.text)\n",
    "    \n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04189e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xlsx(path):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(PATH)\n",
    "    \n",
    "    xml_file = os.path.join(PATH, 'xl/sharedStrings.xml')\n",
    "    \n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for elem in root.iter():\n",
    "        if elem.text:\n",
    "            result.append(elem.text.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82080044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "        openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "        \n",
    "        messages = [\n",
    "            { 'role': 'system', 'content': 'system message here' },\n",
    "            { 'role': 'user', 'content': [\n",
    "                {'type': 'text', 'text': f'Convert the following image into a text table.'},\n",
    "                {'type': 'image_url', 'image_url': { 'url': f'data:image/png;base64,{image}'} }\n",
    "            ]}\n",
    "        ]\n",
    "        \n",
    "        functions = [\n",
    "            {\n",
    "                'name': 'write_queries',\n",
    "                'description': 'Get information from the database',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'details': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The information needed from the database',\n",
    "                        },\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        result = ''\n",
    "        \n",
    "        for chunk in openai.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=messages,\n",
    "            functions=functions,\n",
    "            temperature=0,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            function_call=None,\n",
    "            stream=True\n",
    "        ):\n",
    "            if len(chunk.choices) > 0:\n",
    "                response = chunk.choices[0]\n",
    "                finish_reason = response.finish_reason\n",
    "                content = response.delta.content\n",
    "                function = response.delta.function_call\n",
    "\n",
    "                if content is not None:\n",
    "                    print(content, end='')\n",
    "                    result += content\n",
    "        \n",
    "        return result.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f888cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_files(root_path):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88364573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(s, delimiter = '.'):\n",
    "    parts = s.split(delimiter)\n",
    "    return delimiter.join(parts[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7859f9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "files = collect_all_files(PATH)\n",
    "\n",
    "lines = []\n",
    "for file in files:\n",
    "    lines = []\n",
    "    print(file)\n",
    "    suffix = get_range(file)\n",
    "    if suffix == 'txt':\n",
    "        lines = read_txt(file)\n",
    "    elif suffix == 'pdf':\n",
    "        lines = read_pdf(file)\n",
    "    elif suffix == 'docx':\n",
    "        lines = read_docx(file)\n",
    "    elif suffix == 'pptx':\n",
    "        lines = read_pptx(file)\n",
    "    elif suffix == 'xlsx':\n",
    "        lines = read_xlsx(file)\n",
    "    elif suffix == 'png':\n",
    "        lines = read_png(file)\n",
    "\n",
    "    temp_string = []\n",
    "    print(lines)\n",
    "    for line in lines:\n",
    "        if num_tokens('\\n'.join(temp_string)) > 256:\n",
    "            print('\\n'.join(temp_string))\n",
    "            messages.append('\\n'.join(temp_string))\n",
    "            temp_string = []\n",
    "        else:\n",
    "            temp_string.append(line)\n",
    "    if num_tokens('\\n'.join(temp_string)) < 256:\n",
    "        print('\\n'.join(temp_string))\n",
    "        messages.append('\\n'.join(temp_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470b5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [message for message in messages if len(message) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c5fd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is message 1', 'this is message 2', 'this is message 3', 'this is message 4', 'meow meow', 'woof woof', 'I am a cat']\n"
     ]
    }
   ],
   "source": [
    "if not messages: \n",
    "    messages = [\"this is message 1\", \"this is message 2\", \"this is message 3\", \"this is message 4\", \"meow meow\", \"woof woof\", \"I am a cat\"]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b013bc-e1c8-4fd8-ae89-15c0f6966eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "INDEX = 'idx'\n",
    "\n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "\n",
    "if INDEX not in pc.list_indexes().names():\n",
    "    pc.create_index(INDEX, dimension=1536, metric='cosine', spec=PodSpec(environment=ENV))\n",
    "# connect to index\n",
    "index = pc.Index(INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab3f544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 127\n"
     ]
    }
   ],
   "source": [
    "# calculate embeddings\n",
    "BATCH_SIZE = 128  # you can submit up to 2048 embedding inputs per request\n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(messages), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = messages[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response['data']):\n",
    "        assert i == be['index']  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e['embedding'] for e in response['data']]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({'text': messages, 'embedding': embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64f7bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(df['text']), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(df['text']))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = df['text'][i:i+batch_size]\n",
    "    embeds = df['embedding'][i:i+batch_size]\n",
    "    ids_batch = ['training:' + str(n) for n in range(i, i_end)]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3152ea4f-835b-48af-9faf-df00fbf44af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9213f14b-8696-4912-b588-1e7d817c13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_embeddings(query: str = '', embeddings: dict = {}, max_tokens: int = 1024) -> str:\n",
    "    '''Return the max_tokens amount of related contexts based on the query string.\n",
    "\n",
    "    Keyword arguments:\n",
    "    query -- The query needing context\n",
    "    embeddings -- The list of embeddings and text\n",
    "    max_tokens -- The number of tokens to pull (Default 1024)\n",
    "\n",
    "    Returns:\n",
    "    The context of the query\n",
    "    '''\n",
    "    embedding = openai.Embedding.create(model=EMBEDDING_MODEL, input=query)['data'][0]['embedding']\n",
    "    context = [message for _, message in sorted(zip(cosine_similarity(embeddings['embedding'], [embedding]), embeddings['text']), reverse=True)]\n",
    "\n",
    "    max_tokens = int(max_tokens)\n",
    "\n",
    "    text = ''\n",
    "    total_tokens = 0\n",
    "    max_tokens = min(num_tokens('\\n'.join(context)) + total_tokens + 1, max_tokens + 1)\n",
    "    i = 0\n",
    "\n",
    "    for item in context:\n",
    "        nxt = f'\\n{item}\\n'\n",
    "        total_tokens += num_tokens(nxt)\n",
    "        if total_tokens > max_tokens:\n",
    "            break\n",
    "        text += nxt\n",
    "        i += 1\n",
    "\n",
    "    return f'{text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "588ac2b2-2e07-4ec4-a2fe-ad9ea1490257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bipedal animal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woof woof', 'I am a cat', 'meow meow', 'this is message 2', 'this is message 1', 'this is message 4', 'this is message 3']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quadriped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woof woof', 'this is message 4', 'meow meow', 'this is message 3', 'I am a cat', 'this is message 2', 'this is message 1']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    }
   ],
   "source": [
    "chatbox = ''\n",
    "while chatbox != 'exit':\n",
    "    chatbox = input()\n",
    "    \n",
    "    if chatbox == 'exit':\n",
    "        continue\n",
    "    \n",
    "    index = \"idx\"\n",
    "\n",
    "    # client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "    # STEP 1: Embed your prompt\n",
    "    embedding = openai.Embedding.create(model=EMBEDDING_MODEL, input=chatbox).data[0].embedding\n",
    "\n",
    "    # STEP 2: Initialize pinecone index\n",
    "    pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "\n",
    "    if index in pc.list_indexes().names():\n",
    "        idx = pc.Index(index)\n",
    "        result = idx.query(vector=[embedding], top_k=100, include_metadata=True)\n",
    "        context = [x['metadata']['text'] for x in result['matches']]\n",
    "\n",
    "        print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
